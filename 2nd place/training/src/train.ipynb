{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_beluga.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  \n",
        "drive.mount('/content/drive')   "
      ],
      "metadata": {
        "id": "qHtxgtmOdMV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm pytorch-lightning wandb -qqq -q -U \n",
        "!pip install -U albumentations --no-binary qudida,albumentations"
      ],
      "metadata": {
        "id": "3t7NHTlWdMTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "_xTvzl2ydMRT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_name = \"beluga\"\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/beluga/metadata.csv\")  #\n",
        "out_dir = \"/content/drive/MyDrive/beluga\"                       #\n",
        "\n",
        "!unzip \"/content/drive/MyDrive/beluga/images.zip\"               #\n",
        "train_imgs = \"/content/images\"                                  #"
      ],
      "metadata": {
        "id": "MAdbljXZdc_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = { \n",
        "    \"checkpoint_name\": \"tf_efficientnet_b2_ns_380\",\n",
        "    \"model_name\": \"tf_efficientnet_b2_ns\",\n",
        "    \"batch_size\": 64,\n",
        "    \"image_size\": (380,380),\n",
        "    \"max_epochs\": 20,  \n",
        "\n",
        "    # \"checkpoint_name\": \"tf_efficientnet_b3_ns_380\",\n",
        "    # \"model_name\": \"tf_efficientnet_b3_ns\",\n",
        "    # \"batch_size\": 32,\n",
        "    # \"image_size\": (380,380),\n",
        "    # \"max_epochs\": 30,\n",
        "\n",
        "    # \"checkpoint_name\": \"tf_efficientnet_b4_ns_380\",\n",
        "    # \"model_name\": \"tf_efficientnet_b4_ns\",\n",
        "    # \"batch_size\": 32,\n",
        "    # \"image_size\": (380,380),\n",
        "    # \"max_epochs\": 25,\n",
        "\n",
        "    # \"checkpoint_name\": \"tf_efficientnet_b4_ns_456\",\n",
        "    # \"model_name\": \"tf_efficientnet_b4_ns\",\n",
        "    # \"batch_size\": 24,\n",
        "    # \"image_size\": (456,456),\n",
        "    # \"max_epochs\": 20,\n",
        "\n",
        "    # \"checkpoint_name\": \"tf_efficientnet_b5_ns_456\",\n",
        "    # \"model_name\": \"tf_efficientnet_b5_ns\",\n",
        "    # \"batch_size\": 16,\n",
        "    # \"image_size\": (456,456),\n",
        "    # \"max_epochs\": 22,\n",
        "\n",
        "    # \"checkpoint_name\": \"tf_efficientnet_b5_ns_528\",\n",
        "    # \"model_name\": \"tf_efficientnet_b5_ns\",\n",
        "    # \"batch_size\": 16,\n",
        "    # \"image_size\": (528,528),\n",
        "    # \"max_epochs\": 20,\n",
        "\n",
        "    # \"checkpoint_name\": \"tf_efficientnetv2_m_in21ft1k_380\",\n",
        "    # \"model_name\": \"tf_efficientnetv2_m_in21ft1k\",\n",
        "    # \"batch_size\": 32,\n",
        "    # \"image_size\": (380,380),\n",
        "    # \"max_epochs\": 20,\n",
        "\n",
        "\n",
        "    \"lr_backbone\": 1.6e-3,  \n",
        "    \"lr_head\": 1.6e-2,      \n",
        "    \"lr_decay_scale\": 1.0e-2, \n",
        "    \"out_indices\": (3,4),\n",
        "    \"n_splits\": -1,  # -1, 5,\n",
        "    \"num_classes\": 788,\n",
        "    \"warmup_steps_ratio\": 0.2,\n",
        "    \"n_data\": -1,\n",
        "    \"s_id\": 21.0,               \n",
        "    \"margin_coef_id\": 0.5,      \n",
        "    \"margin_power_id\": -0.125,\n",
        "    \"margin_cons_id\": 0.05,\n",
        "    \"n_center_id\": 2,\n",
        "\n",
        "    \"num_workers\" : 2,\n",
        "    \"wandb\" : False,\n",
        "}"
      ],
      "metadata": {
        "id": "yJ9SkB9UdMPL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg[\"wandb\"]:\n",
        "    wandb.login()"
      ],
      "metadata": {
        "id": "JmYKBBXCWoVk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BelugaDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, data_aug):\n",
        "        super().__init__()\n",
        "        self.index = df.index\n",
        "        self.x_paths = np.array(df.image_id)\n",
        "        self.ids = np.array(df.individual_id, dtype=int) if hasattr(df, \"individual_id\") else np.full(len(df), -1)\n",
        "        self.image_dir = image_dir\n",
        "        self.df = df\n",
        "        self.data_aug = data_aug\n",
        "        augments = []\n",
        "        if data_aug:\n",
        "            augments = [\n",
        "                A.Affine(rotate=(-15, 15),  \n",
        "                         translate_percent=(0.0, 0.25), \n",
        "                         shear=(-3, 3), \n",
        "                         p=0.5),\n",
        "                A.RandomResizedCrop(cfg[\"image_size\"][0], cfg[\"image_size\"][1], \n",
        "                                    scale=(0.9, 1.0), \n",
        "                                    ratio=(0.75, 1.3333333333)),\n",
        "                A.ToGray(p=0.1),\n",
        "                A.GaussianBlur(blur_limit=(3, 7), p=0.05),\n",
        "                A.GaussNoise(p=0.05),\n",
        "                A.RandomGridShuffle(grid=(2, 2), p=0.3),\n",
        "                A.Posterize(p=0.2),\n",
        "                A.RandomBrightnessContrast(p=0.5),\n",
        "                A.CoarseDropout(p=0.05),\n",
        "                A.RandomSnow(p=0.1),\n",
        "                A.RandomRain(p=0.05),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "            ]\n",
        "        augments.append(A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
        "        augments.append(ToTensorV2()) \n",
        "        self.transform = A.Compose(augments)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, i: int):\n",
        "        image = Image.open(f\"{train_imgs}/{self.x_paths[i]}.jpg\").convert(\"RGB\")\n",
        "        image = np.array(image.resize((cfg[\"image_size\"][0], cfg[\"image_size\"][1]), Image.BICUBIC))\n",
        "        augmented = self.transform(image=image)[\"image\"]\n",
        "        return {\n",
        "            \"original_index\": self.index[i],\n",
        "            \"image\": augmented,\n",
        "            \"label\": self.ids[i],\n",
        "        }"
      ],
      "metadata": {
        "id": "jrc-30P2dc65"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WarmupCosineLambda:\n",
        "    def __init__(self, warmup_steps: int, cycle_steps: int, decay_scale: float, exponential_warmup: bool = False):\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.cycle_steps = cycle_steps\n",
        "        self.decay_scale = decay_scale\n",
        "        self.exponential_warmup = exponential_warmup\n",
        "\n",
        "    def __call__(self, epoch: int):\n",
        "        if epoch < self.warmup_steps:\n",
        "            if self.exponential_warmup:\n",
        "                return self.decay_scale * pow(self.decay_scale, -epoch / self.warmup_steps)\n",
        "            ratio = epoch / self.warmup_steps\n",
        "        else:\n",
        "            ratio = (1 + math.cos(math.pi * (epoch - self.warmup_steps) / self.cycle_steps)) / 2\n",
        "        return self.decay_scale + (1 - self.decay_scale) * ratio\n",
        "    \n",
        "def topk_average_precision(output: torch.Tensor, y: torch.Tensor, k: int):\n",
        "    score_array = torch.tensor([1.0 / i for i in range(1, k + 1)], device=output.device)\n",
        "    topk = output.topk(k)[1]\n",
        "    match_mat = topk == y[:, None].expand(topk.shape)\n",
        "    return (match_mat * score_array).sum(dim=1)    \n",
        "\n",
        "def calc_map5(output: torch.Tensor, y: torch.Tensor, threshold: Optional[float]):\n",
        "    if threshold is not None:\n",
        "        output = torch.cat([output, torch.full((output.shape[0], 1), threshold, device=output.device)], dim=1)\n",
        "    return topk_average_precision(output, y, 5).mean().detach()\n",
        "\n",
        "def map_dict(output: torch.Tensor, y: torch.Tensor, prefix: str):\n",
        "    d = {f\"{prefix}/acc\": topk_average_precision(output, y, 1).mean().detach()}\n",
        "    for threshold in [None, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "        d[f\"{prefix}/map{threshold}\"] = calc_map5(output, y, threshold)\n",
        "    return d"
      ],
      "metadata": {
        "id": "m_LtKSzLdc4v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6, requires_grad=False):\n",
        "        super().__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p, requires_grad=requires_grad)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return x.clamp(min=self.eps).pow(self.p).mean((-2, -1)).pow(1.0 / self.p)\n",
        "\n",
        "class ArcMarginProductSubcenter(nn.Module):\n",
        "    def __init__(self, in_features, out_features, k=3):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n",
        "        self.reset_parameters()\n",
        "        self.k = k\n",
        "        self.out_features = out_features\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, features):\n",
        "        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n",
        "        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n",
        "        cosine, _ = torch.max(cosine_all, dim=2)\n",
        "        return cosine\n",
        "\n",
        "class ArcFaceLossAdaptiveMargin(nn.modules.Module):\n",
        "    def __init__(self, margins, n_classes, s = 30.0):\n",
        "        super().__init__()\n",
        "        self.s = s\n",
        "        self.margins = margins\n",
        "        self.out_dim = n_classes\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        ms = self.margins[labels.cpu().numpy()]\n",
        "        cos_m = torch.from_numpy(np.cos(ms)).float().cuda()\n",
        "        sin_m = torch.from_numpy(np.sin(ms)).float().cuda()\n",
        "        th = torch.from_numpy(np.cos(math.pi - ms)).float().cuda()\n",
        "        mm = torch.from_numpy(np.sin(math.pi - ms) * ms).float().cuda()\n",
        "        labels = F.one_hot(labels, self.out_dim).float()\n",
        "        logits = logits.float()\n",
        "        cosine = logits\n",
        "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
        "        phi = cosine * cos_m.view(-1, 1) - sine * sin_m.view(-1, 1)\n",
        "        phi = torch.where(cosine > th.view(-1, 1), phi, cosine - mm.view(-1, 1))\n",
        "        return ((labels * phi) + ((1.0 - labels) * cosine)) * self.s"
      ],
      "metadata": {
        "id": "hCNrSf_AdjRw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BelugaDataModule(LightningDataModule):\n",
        "    def __init__(self, df, image_dir, fold):\n",
        "        super().__init__()\n",
        "        self.image_dir = image_dir\n",
        "        if cfg[\"n_data\"] != -1:\n",
        "            df = df.iloc[: cfg[\"n_data\"]]\n",
        "        self.all_df = df\n",
        "        if fold == -1:\n",
        "            self.train_df = df\n",
        "        else:\n",
        "            skf = StratifiedKFold(n_splits=cfg[\"n_splits\"], shuffle=True, random_state=0)\n",
        "            train_idx, val_idx = list(skf.split(df, df.individual_id))[fold]\n",
        "            self.train_df = df.iloc[train_idx].copy()\n",
        "            self.val_df = df.iloc[val_idx].copy()\n",
        "            new_mask = ~self.val_df.individual_id.isin(self.train_df.individual_id)\n",
        "            self.val_df.individual_id.mask(new_mask, cfg[\"num_classes\"], inplace=True)\n",
        "\n",
        "    def get_dataset(self, df, data_aug):\n",
        "        return BelugaDataset(df, self.image_dir, data_aug)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        dataset = self.get_dataset(self.train_df, True)\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=cfg[\"batch_size\"],\n",
        "            shuffle=True,\n",
        "            num_workers = cfg[\"num_workers\"],\n",
        "            pin_memory=True,\n",
        "            drop_last=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        if cfg[\"n_splits\"] == -1:\n",
        "            return None\n",
        "        return DataLoader(\n",
        "            self.get_dataset(self.val_df, False),\n",
        "            batch_size=cfg[\"batch_size\"],\n",
        "            shuffle=False,\n",
        "            num_workers = cfg[\"num_workers\"],\n",
        "            pin_memory=True,\n",
        "        )"
      ],
      "metadata": {
        "id": "-2OcQgGO25xl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BelugaClassifier(LightningModule):\n",
        "    def __init__(self, id_class_nums=None):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(cfg, ignore=[\"id_class_nums\"])\n",
        "        self.test_results_fp = None\n",
        "\n",
        "        self.backbone = timm.create_model(\n",
        "            cfg[\"model_name\"],\n",
        "            in_chans=3,\n",
        "            pretrained=True,\n",
        "            num_classes=0,\n",
        "            features_only=True,\n",
        "            out_indices=cfg[\"out_indices\"],\n",
        "        )\n",
        "        feature_dims = self.backbone.feature_info.channels()\n",
        "        self.global_pools = torch.nn.ModuleList([GeM(p=3, requires_grad=False) for _ in cfg[\"out_indices\"]])\n",
        "        self.mid_features = np.sum(feature_dims)\n",
        "        self.neck = torch.nn.BatchNorm1d(self.mid_features)\n",
        "        self.head_id = ArcMarginProductSubcenter(self.mid_features, cfg[\"num_classes\"], cfg[\"n_center_id\"])\n",
        "        margins_id = np.power(id_class_nums, cfg[\"margin_power_id\"]) * cfg[\"margin_coef_id\"] + cfg[\"margin_cons_id\"]\n",
        "        self.margin_fn_id = ArcFaceLossAdaptiveMargin(margins_id, cfg[\"num_classes\"], cfg[\"s_id\"])\n",
        "        self.loss_fn_id = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def get_feat(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        ms = self.backbone(x)\n",
        "        h = torch.cat([global_pool(m) for m, global_pool in zip(ms, self.global_pools)], dim=1)\n",
        "        return self.neck(h)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        feat = self.get_feat(x)\n",
        "        return self.head_id(feat)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, ids = batch[\"image\"], batch[\"label\"]\n",
        "        logits_ids = self(x)\n",
        "        margin_logits_ids = self.margin_fn_id(logits_ids, ids)\n",
        "        loss_ids = self.loss_fn_id(margin_logits_ids, ids)\n",
        "        self.log_dict({\"train/loss_ids\": loss_ids.detach()}, on_step=False, on_epoch=True)\n",
        "        with torch.no_grad():\n",
        "            self.log_dict(map_dict(logits_ids, ids, \"train\"), on_step=False, on_epoch=True)\n",
        "        return loss_ids\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, ids = batch[\"image\"], batch[\"label\"]\n",
        "        out1 = self(x)\n",
        "        out2 = self(x.flip(3))\n",
        "        output = (out1 + out2) / 2\n",
        "        self.log_dict(map_dict(output, ids, \"val\"), on_step=False, on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        backbone_params = list(self.backbone.parameters()) + list(self.global_pools.parameters())\n",
        "        head_params = (list(self.neck.parameters()) + list(self.head_id.parameters()))\n",
        "        params = [\n",
        "            {\"params\": backbone_params, \"lr\": cfg[\"lr_backbone\"]},\n",
        "            {\"params\": head_params, \"lr\": cfg[\"lr_head\"]},\n",
        "        ]\n",
        "\n",
        "        optimizer = torch.optim.AdamW(params)\n",
        "\n",
        "        warmup_steps = cfg[\"max_epochs\"] * cfg[\"warmup_steps_ratio\"]\n",
        "        cycle_steps = cfg[\"max_epochs\"] - warmup_steps\n",
        "        lr_lambda = WarmupCosineLambda(warmup_steps, cycle_steps, cfg[\"lr_decay_scale\"])\n",
        "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "        return [optimizer], [scheduler]"
      ],
      "metadata": {
        "id": "LWOg1t1NdjPV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(df, fold):\n",
        "    out_dr = f\"{out_dir}/{exp_name}\"\n",
        "    id_class_nums = df.individual_id.value_counts().sort_index().values\n",
        "    model = BelugaClassifier(id_class_nums=id_class_nums)\n",
        "    data_module = BelugaDataModule(df, f\"{train_imgs}\", fold)\n",
        "    loggers = [pl_loggers.CSVLogger(out_dr)]\n",
        "    if cfg[\"wandb\"]:\n",
        "        loggers.append(\n",
        "            pl_loggers.WandbLogger(\n",
        "                project=\"beluga_\", group=exp_name, name=f\"{exp_name}\", save_dir=out_dir\n",
        "            )\n",
        "        )\n",
        "    checkpoint_callback = ModelCheckpoint(out_dir, save_last=True, save_top_k=0)\n",
        "    checkpoint_callback.CHECKPOINT_NAME_LAST = cfg[\"checkpoint_name\"]\n",
        "\n",
        "    trainer = Trainer(\n",
        "        gpus=1,\n",
        "        max_epochs=cfg[\"max_epochs\"],\n",
        "        logger=loggers,\n",
        "        callbacks=[checkpoint_callback],\n",
        "        precision=16,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, datamodule=data_module)\n",
        "\n",
        "    if cfg[\"wandb\"]:\n",
        "        wandb.finish()"
      ],
      "metadata": {
        "id": "Z0PHntiNdjM1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoder\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df[\"individual_id\"] = label_encoder.fit_transform(df[\"whale_id\"])\n",
        "assert cfg[\"num_classes\"] == len(label_encoder.classes_)\n",
        "\n",
        "if cfg[\"n_splits\"] == -1:\n",
        "    train(df, -1)\n",
        "else:\n",
        "    train(df, 0)"
      ],
      "metadata": {
        "id": "FvM0t3_OdjKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rTjMXsMW0nS6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}